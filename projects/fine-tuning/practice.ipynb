{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSWEcS2XKgzi"
      },
      "source": [
        "### Practice: Parameter Efficient Fine-Tuning\n",
        "In this notebook, you're gonna fine-tune large language models within limited GPU memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7xeRF_hSKgzs"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet transformers==4.34.1 accelerate==0.24.0 sentencepiece==0.1.99 optimum==1.13.2 peft==0.5.0 bitsandbytes==0.41.2.post2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import transformers\n",
        "from tqdm.auto import tqdm, trange\n",
        "assert torch.cuda.is_available(), \"you need cuda for this part\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VMzFwx29Kgzu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "a329a6a8b64744a89169ad95ebdabaa8",
            "858e81c7a88747338400a8628c23cdbd",
            "b255ffb1028948ac8f60e77b9221db39",
            "b12ec7cfaaf3407ebf0406ab77734b8f",
            "d406425bcbdb4d43a56c3daee817293b",
            "a5ae8fbe36c54d658d549339d90d1944",
            "d89739d602374604aa24d738426b527b",
            "b775b1a1571840c4a4a0148ca4f0bc61",
            "fbf2db5922824438840f45fc4b74ae72",
            "ba542e31f14c4ca19dd144890d9afde2",
            "3c50d988d3e543a79ddb352a77a5a50b"
          ]
        },
        "outputId": "50cfd5d2-58de-487e-ea1a-cb2277195403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a329a6a8b64744a89169ad95ebdabaa8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = 'Enoch/llama-7b-hf'\n",
        "\n",
        "# loading Llama tokenizer ...\n",
        "tokenizer = transformers.LlamaTokenizer.from_pretrained(model_name, device_map=device)\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# ... and the model itself\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_name, device_map='auto', low_cpu_mem_usage=True, offload_state_dict=True,\n",
        "    load_in_4bit=True, torch_dtype=torch.float32,  # weights are 4-bit; layernorms and activations are fp32\n",
        ")\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "\n",
        "model.gradient_checkpointing_enable()  # only store a small subset of activations, re-compute the rest.\n",
        "model.enable_input_require_grads()     # override an implementation quirk in gradient checkpoints that disables backprop unless inputs require grad\n",
        "# more on gradient checkpointing: https://pytorch.org/docs/stable/checkpoint.html https://arxiv.org/abs/1604.06174"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt tuning: the story of a fox (2 pts)\n",
        "\n",
        "![img](https://i.imgur.com/Ux3qQAu.png) (source: theodd1souts.fandom.com)"
      ],
      "metadata": {
        "id": "rgspB2JwSIS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'A quick brown fox'\n",
        "batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "\n",
        "for i in range(10):\n",
        "    next_token = model(**batch).logits[0, -1].argmax(-1).reshape(1, 1)\n",
        "    batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
        "    batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
        "\n",
        "print(\"\\nOutput:\", tokenizer.decode(batch['input_ids'][0].cpu().numpy().tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H13pYFRxQi4U",
        "outputId": "0a91b782-b04f-4e63-a834-b1815ecd6572"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output: <s>A quick brown fox jumps over the lazy dog.\n",
            "A quick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What a blatant lie! This particular fox assures you that it didn't in fact jump over the lazy dog. No, sir! The fox was just minding its own business. __Your task is to train the model to say truth: no dog was jumped over today.__"
      ],
      "metadata": {
        "id": "VVhZACT6SgLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "the_truth = \"A quick brown fox did not jump over the lazy dog. Besides, that dog deserved it anyway!\"\n",
        "batch = tokenizer(the_truth, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "outputs = model(**batch)\n",
        "\n",
        "next_word_logits = outputs.logits[:, :-1]\n",
        "true_next_tokens = batch['input_ids'][:, 1:]\n",
        "loss = F.cross_entropy(next_word_logits.flatten(0, 1), true_next_tokens.flatten(0, 1))\n",
        "\n",
        "print(\"Loss:\", loss)"
      ],
      "metadata": {
        "id": "_r6UVDl4NEua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a769b20c-777f-42f4-9d1d-a170a70d6ac8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(3.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Except, we can't train the entire model - that would be 28GB gradients in float32. Instead, let's run [prompt tuning](https://arxiv.org/abs/2104.08691).\n",
        "\n",
        "![img](https://i.imgur.com/VwNNKnb.png)\n"
      ],
      "metadata": {
        "id": "amvNufS8WXa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WordEmbeddingsWithLearnedPrompts(nn.Module):\n",
        "    \"\"\"\n",
        "    To perform prompt tuning, you will need to replace model's original word embeddings with a layer - THIS layer\n",
        "     - that inserts trainable prompts instead of the first N token embeddings. \"\"\"\n",
        "\n",
        "    def __init__(self, word_embeddings: nn.Embedding, num_prompts: int):\n",
        "        super().__init__()\n",
        "        self.original_word_embeddings = word_embeddings\n",
        "        self.num_prompts = num_prompts\n",
        "        self.learnable_prompts = nn.Parameter(\n",
        "            torch.randn(1, num_prompts, word_embeddings.embedding_dim), requires_grad=True)\n",
        "\n",
        "    def forward(self, input_ids: torch.LongTensor):\n",
        "        # input_ids shape: [batch_size, seq length]\n",
        "        assert input_ids.dtype == torch.int64\n",
        "        assert input_ids.shape[1] > self.num_prompts\n",
        "        assert torch.all(input_ids[:, :self.num_prompts] == tokenizer.pad_token_id).item(), \"don't forget to prepend several BOS tokens to input_ids\"\n",
        "\n",
        "        # Your task: embed input_ids, but replace the first :num_prompts: tokens with self.learnable_prompts\n",
        "        # This is because we will prepend :num_prompts: padding tokens at the beginning\n",
        "\n",
        "        # After you are done, you must produce a word embedding vector for each token in input_ids,\n",
        "        # except that the first :num_prompts: vectors should equal learnable_prompts;\n",
        "        # any additional vectors after first :num_prompts: ones should be embedded as usual\n",
        "        # Note: since you're dealing with trainable params, please torch.cat instead of item assignment\n",
        "\n",
        "        embed_input = self.original_word_embeddings(input_ids)\n",
        "\n",
        "        return torch.cat((self.learnable_prompts, embed_input[:,self.num_prompts:,:]), dim=1)"
      ],
      "metadata": {
        "id": "73ZOCFRZWR98"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_prompts = 16\n",
        "test_emb_layer = WordEmbeddingsWithLearnedPrompts(model.model.embed_tokens, num_prompts=num_prompts).to(device)\n",
        "test_input_ids = tokenizer(\"a cat say on a may\", return_tensors='pt')['input_ids'].to(device)\n",
        "\n",
        "space_for_prompts = torch.full([len(test_input_ids), num_prompts], fill_value=tokenizer.pad_token_id,\n",
        "                               dtype=torch.int64, device=device)\n",
        "test_inputs_with_prompts = torch.cat([space_for_prompts, test_input_ids], dim=1)\n",
        "\n",
        "with torch.cuda.amp.autocast():\n",
        "  test_prompt_embeddings = test_emb_layer(test_inputs_with_prompts)\n",
        "\n",
        "assert test_prompt_embeddings.shape[:2] == test_inputs_with_prompts.shape\n",
        "assert test_prompt_embeddings.shape[-1] == model.config.hidden_size\n",
        "assert torch.allclose(test_prompt_embeddings[:, :num_prompts], test_emb_layer.learnable_prompts.float())\n",
        "assert torch.allclose(test_prompt_embeddings[:, num_prompts:], model.model.embed_tokens(test_input_ids).float())\n",
        "print(\"Looks legit!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxUyUU2uT2f1",
        "outputId": "78abf440-fd05-40f0-f4a0-87bbc3b4f811"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks legit!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Now that it works,__ let's inject learnable prompts into the main model and teach it about foxes."
      ],
      "metadata": {
        "id": "FbKPgfT-crqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert isinstance(model.model.embed_tokens, nn.Embedding), \"you have already replaced the embedding layer. If the replacement is broken, please reload the model\"\n",
        "\n",
        "model.model.embed_tokens = WordEmbeddingsWithLearnedPrompts(model.model.embed_tokens, num_prompts=num_prompts).to(device)\n",
        "\n",
        "opt = torch.optim.Adam([model.model.embed_tokens.learnable_prompts], lr=0.01)"
      ],
      "metadata": {
        "id": "QRe0lpREV49G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_truth = \"A quick brown fox did not jump over the lazy dog. Besides, that dog deserved it anyway!\"\n",
        "batch = tokenizer(the_truth, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "space_for_prompts = torch.full([len(test_input_ids), num_prompts], fill_value=tokenizer.pad_token_id,\n",
        "                               dtype=torch.int64, device=device)\n",
        "batch['input_ids'] = torch.cat([space_for_prompts, batch['input_ids']], dim=1)\n",
        "batch['attention_mask'] = torch.cat([torch.ones_like(space_for_prompts), batch['attention_mask']], dim=1)\n",
        "\n",
        "# raise NotImplemented(\"Your task: iteratively train the model to reduce loss using prompt optimizer (opt)\")\n",
        "while loss.item() > 0.1:\n",
        "  outputs = model(**batch)\n",
        "  next_word_logits = outputs.logits[:, num_prompts : -1, :]\n",
        "  true_next_tokens = batch['input_ids'][:, num_prompts + 1:]\n",
        "  loss = F.cross_entropy(next_word_logits.flatten(0, 1), true_next_tokens.flatten(0, 1))\n",
        "  print(\"Loss:\", loss)\n",
        "  loss.backward()\n",
        "  # For adjusting learning weights\n",
        "  opt.step()\n",
        "\n",
        "assert loss.item() <= 0.1\n",
        "print(\"Good job!\")"
      ],
      "metadata": {
        "id": "3gVQzgdka-Bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "921e0aca-cc3d-4c46-b5f2-c3042ccec379"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(8.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(7.0681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(6.5808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(6.2484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.9810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.6683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.4166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.3863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.9604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.8096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.6780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.5582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.4519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.2519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.1448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.8991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.7582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.4654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.3486, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.2775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.2583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.2946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.3716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.4345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.4806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.4964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.3927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.2215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.8907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.7415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.4974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.4033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.3323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.1978, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.1981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.3125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.1473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.0759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.9835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.9520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.9190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.8814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.8389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.7930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.7458, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.6988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.6532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.5943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.6399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.8378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.9935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.7511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.5232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.4667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.4618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.4459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.4147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.3745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.3291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.2808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.2316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.1831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.1367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.0932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.2495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.4339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.4641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.3473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.1074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9868, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9768, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.7877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.7172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6461, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5455, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4788, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.7532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.7873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.7354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2933, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3594, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3703, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3771, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3770, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3744, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2702, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2822, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2563, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1348, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1232, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0974, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Good job!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'A quick brown fox'\n",
        "batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "batch['input_ids'] = torch.cat([space_for_prompts, batch['input_ids']], dim=1)\n",
        "batch['attention_mask'] = torch.cat([torch.ones_like(space_for_prompts), batch['attention_mask']], dim=1)\n",
        "\n",
        "\n",
        "for i in range(15):\n",
        "    next_token = model(**batch).logits[0, -1].argmax(-1).reshape(1, 1)\n",
        "    batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
        "    batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
        "\n",
        "print(\"\\nOutput:\", tokenizer.decode(batch['input_ids'][0, num_prompts:].cpu().numpy().tolist()))\n",
        "\n",
        "# if you did everything right, the model will deny that the fox jumped over the lazy dog"
      ],
      "metadata": {
        "id": "F7DkWHD-r1Xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f72e26-80cc-4ecf-d827-aeb80b4478a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output: <s>A quick brown fox did not jump over the lazy dog. Besides, that dog deserved it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using HuggingFace PEFT (2 points)\n",
        "\n",
        "[`peft`](https://huggingface.co/docs/peft/index) is a transformer's sister library that allows you to apply various __p__arameter __e__fficient __f__ine-__t__uning methods to pre-trained transformers. The library imlements both prompt tuning, prefix tuning, as well as several adapter-based techniques under a common interface:\n",
        "\n"
      ],
      "metadata": {
        "id": "sEkoFNdlshv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import peft\n",
        "assert isinstance(model.model.embed_tokens, nn.Embedding), \"please reload the model\"\n",
        "\n",
        "peft_config = peft.PromptTuningConfig(task_type=peft.TaskType.CAUSAL_LM, num_virtual_tokens=16)\n",
        "model = peft.get_peft_model(model, peft_config)  # note: for most peft methods, this line also modifies model in-place\n",
        "print(\"Trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "print(\"Total parameters (excluding quantization):\", sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "mqEEpZm2Q4UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155d18ad-6144-4ba9-d191-d8be0cd91580"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 65536\n",
            "Total parameters (excluding quantization): 3500478464\n",
            "trainable params: 65,536 || all params: 6,738,481,152 || trainable%: 0.0009725633792200893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_virtual_tokens = 16\n",
        "the_truth = \"A quick brown fox did not jump over the lazy dog. Besides, that dog deserved it anyway!\"\n",
        "batch = tokenizer(the_truth, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "outputs = model(**batch)\n",
        "\n",
        "next_word_logits = outputs.logits[:, num_virtual_tokens : -1, :]\n",
        "true_next_tokens = batch['input_ids'][:, 1:]\n",
        "loss = F.cross_entropy(next_word_logits.flatten(0, 1), true_next_tokens.flatten(0, 1))\n",
        "\n",
        "print(\"Loss:\", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdcupyKJeRnB",
        "outputId": "af7932b1-2649-4ca8-932c-d843cd42782e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(8.5552, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your task: optimize the PEFT-wrapped model to achieve next token prediction loss < 0.1, but this time using PEFT\n",
        "# Please note: you no longer need to prepend PAD tokens, but you still need to skip :num_virtual_tokens: first logits.\n",
        "# Finally, generate the sentence to make sure that the model learned the truth.\n",
        "\n",
        "the_truth = \"A quick brown fox did not jump over the lazy dog. Besides, that dog deserved it anyway!\"\n",
        "batch = tokenizer(the_truth, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "while loss.item() > 0.1:\n",
        "  outputs = model(**batch)\n",
        "  next_word_logits = outputs.logits[:, num_virtual_tokens : -1, :]\n",
        "  true_next_tokens = batch['input_ids'][:, 1:]\n",
        "  loss = F.cross_entropy(next_word_logits.flatten(0, 1), true_next_tokens.flatten(0, 1))\n",
        "  print(\"Loss:\", loss)\n",
        "  loss.backward()\n",
        "  # For adjusting learning weights\n",
        "  opt.step()\n",
        "\n",
        "assert loss.item() <= 0.1\n",
        "print(\"Good job!\")"
      ],
      "metadata": {
        "id": "UW54GnzCwVpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236309b4-aeff-4cdf-91f7-f07f7fa0644a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(8.5552, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(7.3104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(6.8733, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(6.5592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(6.2784, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(6.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.7420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.4874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.2670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(5.0949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.9669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.8687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.7858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.7076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.6275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.5433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.4599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.4004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.4265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.4298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.2347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(4.0224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.9012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.8440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.8029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.7538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.6975, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.6412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.5915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.5536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.5286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.5104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.4869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.4438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.3760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.2924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.2075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.1311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.0655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(3.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.9518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.8954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.8367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.7755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.7125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.6487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.5849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.5220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.4607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.4019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.3457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.2408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.1911, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.1431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.0976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.0569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.0245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(2.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.9917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.9753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.9389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.8866, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.8362, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.7972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.7681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.7445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.7224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.6996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.6751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.6485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.6197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.5887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.5554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.5200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.4827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.4439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.4045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.3656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.3283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.2935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.2615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.2323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.2057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.1810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.1577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.1351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.1125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.0893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.0648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.0384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(1.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.9198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.8615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.7959, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.7289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6551, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.6010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5806, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.5130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4231, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4224, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.4108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3999, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.3122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2639, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2423, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2605, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.2005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1886, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1484, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1480, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1469, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1363, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.1012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Loss: tensor(0.0994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Good job!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feel free to structure your code as you see fit - as long as it's legible :)\n",
        "\n",
        "prompt = 'A quick brown fox'\n",
        "batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "\n",
        "for i in range(16):\n",
        "    next_token = model(**batch).logits[0, -1].argmax(-1).reshape(1, 1)\n",
        "    batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
        "    batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
        "\n",
        "print(\"\\nOutput:\", tokenizer.decode(batch['input_ids'][0].cpu().numpy().tolist()))\n",
        "\n",
        "# if you did everything right, the model will deny that the fox jumped over the lazy dog"
      ],
      "metadata": {
        "id": "71vJ9Mq7w67f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f84f139-dac0-4d34-f602-6f32d5fcb736"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output: <s>A quick brown fox did not jump over the lazy dog. Besides, that dog deserved it anyway\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter-efficient finetuning with LoRA (2 points)\n",
        "\n",
        "When training on more serious tasks, you can use low-rank adapters based on the [LoRA paper](https://arxiv.org/pdf/2106.09685.pdf).\n",
        "\n",
        "The core idea is to add low-rank adapters __in parallel with existing linear layers,__ like this:\n",
        "<center><img src=\"https://i.imgur.com/6bQLNiG.png\" width=240px></center>\n",
        "\n",
        "In the original LoRA paper, the adapters were only added to attention projection matrices. However, [subsequent works](https://arxiv.org/abs/2305.14314) show that it is useful to adapt FFNs as well. But before we do any training, we need to implement the basic LoRA layer."
      ],
      "metadata": {
        "id": "uCkpKYjWxfhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# re-load the model to remove any previous PEFT tuners\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_name, device_map='auto', low_cpu_mem_usage=True, offload_state_dict=True,\n",
        "    load_in_4bit=True, torch_dtype=torch.float32,  # weights are 4-bit; layernorms and activations are fp32\n",
        ")\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "39ac305e3f324b3f8eea2ec632e2f39f",
            "3c97662de5524e559f30020db379558e",
            "bb6641fbf9ae4eed87a7be96b9dadb6b",
            "198a6e41a37545f18264c3eb1ea7907c",
            "6d094b23993d41b9a72dca4ba98c6bba",
            "62e46427e479410c8b67bd9e01a05be6",
            "e5ca6cbc9bba431d934c4016381fe517",
            "70e66dcdd2ee44b89e07dc1e0bc6b401",
            "b15e7e3336e94438916f784ca820d43d",
            "22208d8762a24cb59b775d05055618b6",
            "91e369c44ef245d4b740dfdc3259d9c3"
          ]
        },
        "id": "8zundaSzx90r",
        "outputId": "a625d603-a727-425a-916d-434b18bbdef7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39ac305e3f324b3f8eea2ec632e2f39f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRALayer(nn.Module):\n",
        "    \"\"\"Wraps a linear layer with LoRA-like adapter. Wraps an existing OPT linear layer\"\"\"\n",
        "    def __init__(self, module: nn.Linear, rank: int):\n",
        "        super().__init__()\n",
        "        self.module = module  # pre-trained (frozen) linear layer\n",
        "        self.adapter_A = nn.Parameter(torch.empty(module.in_features, rank, device=module.weight.device))\n",
        "        nn.init.kaiming_uniform_(self.adapter_A, a=5 ** 0.5)\n",
        "        self.adapter_B = nn.Parameter(torch.zeros(rank, module.out_features, device=module.weight.device))\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Apply self.module and LoRA adapter, return the sum (self.module outputs + adapter outputs)\n",
        "        module_output = self.module(input)\n",
        "        adapter_output = torch.matmul(torch.matmul(input, self.adapter_A), self.adapter_B)\n",
        "        return module_output + adapter_output"
      ],
      "metadata": {
        "id": "MJ_hq4fwyPVR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test your implementation\n",
        "test_linear = nn.Linear(128, 128)\n",
        "test_linear.weight.data[...] = torch.eye(128)\n",
        "test_adapter = LoRALayer(test_linear, rank=8)\n",
        "\n",
        "assert torch.allclose(test_adapter(torch.ones(1, 1, 128)), test_linear.bias + 1), \"please check your forward pass\"\n",
        "\n",
        "test_adapter.adapter_A.data[...] = torch.linspace(0.1, -0.5, 128 * 8).view(128, 8)\n",
        "test_adapter.adapter_B.data[...] = torch.linspace(0.5, -0.1, 128 * 8).view(8, 128)\n",
        "test_linear.bias.data[...] = torch.linspace(1., -1., 128)\n",
        "\n",
        "dummy_loss = F.mse_loss(test_adapter(torch.ones(1, 128) / 128).squeeze(), torch.linspace(-1, 1, 128))\n",
        "assert torch.allclose(dummy_loss, torch.tensor(1.3711389), rtol=0, atol=1e-4)\n",
        "dummy_loss.backward()\n",
        "assert all(w.grad is not None for w in [test_adapter.adapter_A, test_adapter.adapter_B]), \"some adapter weights have no grad\"\n",
        "assert torch.allclose(test_adapter.adapter_A.grad.sum(), torch.tensor(-0.60158), rtol=0, atol=1e-4), \"bad grad w.r.t. A\"\n",
        "assert torch.allclose(test_adapter.adapter_B.grad.sum(), torch.tensor(0.9931), rtol=0, atol=1e-4), \"bad grad w.r.t. B\"\n",
        "# note: bad grad means that your code is different from LoRA paper OR that your code is not autograd-friendly (e.g. no_grad)\n",
        "del dummy_loss, test_linear, test_adapter\n",
        "print(\"All tests passed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTzOs65JydcS",
        "outputId": "7f08fb4f-6aee-4c3a-ab1a-e65498ae7b5a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tajVTsvLulB6"
      },
      "source": [
        "### Apply LoRA to the model\n",
        "\n",
        "The code below applies LoRA adapters on top of Q/K/V linear layers in Llama attention. You may also choose to modify other layers:\n",
        "* self_attn.o_proj - attention output projection\n",
        "* mlp.up_proj, mlp.gate_proj, mlp.down_proj - transformer feedforward layers\n",
        "* lm_head - output LM head\n",
        "\n",
        "__Note:__ please scroll down for the homework task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "davyUVEwulB6"
      },
      "outputs": [],
      "source": [
        "lora_rank = 8\n",
        "\n",
        "for name, module in model.model.layers.named_modules():\n",
        "    if 'LlamaDecoderLayer' in repr(type(module)):\n",
        "        module.self_attn.q_proj = LoRALayer(module.self_attn.q_proj, rank=lora_rank).to(device)\n",
        "        module.self_attn.k_proj = LoRALayer(module.self_attn.k_proj, rank=lora_rank).to(device)\n",
        "        module.self_attn.v_proj = LoRALayer(module.self_attn.v_proj, rank=lora_rank).to(device)\n",
        "\n",
        "assert sum(isinstance(module, LoRALayer) for module in model.modules()) == 96  # for Llama-7B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": [],
        "id": "AWzfvc0EulB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f52fb08-10a9-446f-82b7-e53d3f9a1111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grad check successful, well done!\n"
          ]
        }
      ],
      "source": [
        "batch = tokenizer(\"This model wants to share its greatest secret:\", return_tensors='pt', return_token_type_ids=False)\n",
        "# test a single training step, make sure we get meaningful gradients\n",
        "with torch.cuda.amp.autocast(dtype=torch.float32):\n",
        "    out = model.forward(**batch)\n",
        "    (out.logits.norm() / 100).backward()\n",
        "\n",
        "for i, module in enumerate(model.modules()):\n",
        "    if isinstance(module, LoRALayer):\n",
        "        assert module.adapter_B.grad is not None\n",
        "        assert module.adapter_B.grad.norm().item() > 0\n",
        "\n",
        "model.zero_grad(set_to_none=True)\n",
        "print(\"Grad check successful, well done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjIJ1vkUulB7"
      },
      "source": [
        "### (example) How to train your model\n",
        "\n",
        "The example below shows how to train the LoRA adapters on a dummy dataset. You will need to run a _similar_ training task later.\n",
        "\n",
        "__Note:__ please scroll down for the homework task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "r9mIpntHulB8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9eb3ecfcbdf24b23ba8ca84781dacb0b",
            "706396b698834bb9b097ed58597322a5",
            "16d0d9d3a38340e3a4c4503a4478ac17",
            "aaa70432b21f489784b04ef82a59786c",
            "49a6a5cd71d7451890d8b3cd293e9b27",
            "2d7254f1a78c4717b682effd1ff29e56",
            "5e47bc789124454a92f0641754819846",
            "5016c9b3498f4d2aaefe41fce53e391d",
            "bf4159bcbd3d4c65aba85e0fec0cd99e",
            "be89da3a2cec4974944768aa57bea11d",
            "e9032f92777149ebb6d9fc731bf6ca5d",
            "02a7585097f84b66aebd751de8da0f45",
            "0cd4214f933d4af29e50894638133822",
            "6d759ddbb1f54171a1ee0573badd9494",
            "4df241f871044c4883dc48b718980d92",
            "9d52e41f13b6463eb9a112753fb3b436",
            "9eea5c1a381d4c7297d54f9a6df26ac8",
            "ca053a6586a34247b0807a0944df37f0",
            "98904bd648814109baf6065a09689c19",
            "e8d3352ea16e4b15bf48b9328f1426a8",
            "edf77db4d4ff40839a96cd30a6205cac",
            "66a69c3957b241b087e5876189de55b0",
            "30c91da2c9b04ebca063b8617b7e89f4",
            "e3258a9d352b48e7ae01e3144926e440",
            "34099d8a6ea14ffdadfa49c548a7f9c6",
            "da88d4f959ad49abb35b3b01e37d2c4e",
            "2680953fa70c42cf9151ccbc01e74eee",
            "e90ddfb610e645a4b92a9ff3a4a1cfb9",
            "3fbfd9c3b3284a549a318471d909a1ad",
            "b5bea63f1c484bbab47693e83be6d5ab",
            "6955812674514ddeb517c3519479e572",
            "eb05f16e8f7a472aa6c0429dab56f51a",
            "743acf7508644f5d926ea4996b100651",
            "9be683454d72411aa7510e4921dfad3b",
            "056079080e6341abbf85f9e83b8fc34e",
            "4f323495be4f47c9a319d3a0037273ae",
            "4f2e79bdf7bf4bf1b054cdf6532813cc",
            "706a3ed1bdf3416fa00c08b44e8a333a",
            "226895417e134d669f6745bb5d3df801",
            "aadd4898ec3b4b85b6669c2ac1f05a09",
            "cfa02f59ef94484da6b80b53cae8dfff",
            "08c050680a484a60aa8750d6cac45954",
            "c4abe53249054f6681c7f9cf0bf6e511",
            "9aa8c435f20a4f3196c659664c876983",
            "5ee71b6786064a24aa3363dbd06b6922",
            "a200ee71463f45e8932b5f8ec1526513",
            "87c123d817244f8890ed6c4031f79e4d",
            "2fbc1f01584b4ddea111d8ec6e6d0685",
            "e9692c35afd94173a876f9dc2d5f2d07",
            "de6b07d47bb241e6ac59c5c5beb3a99c",
            "b15ec39fa2f04d7f9ca49b4c4b63c734",
            "d75b5e23e1724cd2a7102019e76ad376",
            "1164b8c26fe24602ba38b00fd1353bdb",
            "bacd536b97f2495a91c6a6dd05b72d6b",
            "8efcd648e0c14e408e0a798753c7ca20",
            "d733b07b93354e568ca792e42104facd",
            "0901b10cba4a466398ad776fde2c9b31",
            "19b1fa310e584f8f99fb1e45b8ec321a",
            "93bac674cbc349008dfc912e6e0da7d4",
            "d21d6cd06aa34884996ce98ed6f20e30",
            "68e10453dfa34bfebaeafde9f94bc65c",
            "98e94f5a16dc4388bdfe24de5253242a",
            "e544f81fe96f43b4b6d430864f95e1cf",
            "aaedbdb4be834d009fd4cd6038fe9d48",
            "480261bc7b214a8699fa6b862a9d4876",
            "1d1913cebd9945c9a443bbaea1412f01"
          ]
        },
        "outputId": "843321d8-dbef-4ca2-f68d-d364451bd7fd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/5.55k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9eb3ecfcbdf24b23ba8ca84781dacb0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02a7585097f84b66aebd751de8da0f45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/647k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30c91da2c9b04ebca063b8617b7e89f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9be683454d72411aa7510e4921dfad3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ee71b6786064a24aa3363dbd06b6922"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d733b07b93354e568ca792e42104facd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 02:31, Epoch 6/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.891200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.696000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.897000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.745800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.169500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.734200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.537100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.084100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.674700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.442000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.043300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.368400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.354900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.035200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.271300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.633800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.427400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.303000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.162200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.081800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.471300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.824100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.557900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.729000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.766400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.193800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.198300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.964000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.787600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.870500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.937200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.672300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.732800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.332800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.150600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.572300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.512600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.668800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.786800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.491200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.867500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.399300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.150700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.291800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.287400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.637700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.756900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.683800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.116000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.472000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.268400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.089100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.432900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.492600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.286800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.859600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.689800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.225400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.421000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.255300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.413300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.203200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.201100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.297300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.184600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.185300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.156300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.271200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.321500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.285700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.087300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.534900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.166900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.407600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.486800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.478600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.266400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.221900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.284700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.087800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.322300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.207600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.041400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.127100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.283900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.221900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.391200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.126500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.132600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.243300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.204700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.278000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.112900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.083100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.288800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.401300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.212200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.208700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.163900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=0.5408306780830026, metrics={'train_runtime': 152.7295, 'train_samples_per_second': 1.31, 'train_steps_per_second': 0.655, 'total_flos': 621258424123392.0, 'train_loss': 0.5408306780830026, 'epoch': 6.25})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# checking if the model can learn. Change max_steps for proper training\n",
        "import datasets\n",
        "data = datasets.load_dataset(\"Abirate/english_quotes\", split=\"train[:32]\") # 32 lines\n",
        "data = data.map(lambda samples: tokenizer(samples['quote']), batched=True)\n",
        "model._hf_peft_config_loaded = True  # silence a warning from HF trainer\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model, train_dataset=data,\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=2, gradient_accumulation_steps=1,\n",
        "        # note: if you want larger batch size, increase gradient_accumulation_steps\n",
        "        warmup_steps=250, max_steps=100, learning_rate=2e-4, fp16=True,\n",
        "        logging_steps=1, output_dir='outputs', report_to=None),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "# if you see cache warnings, set `model.config.use_cache = False` to silence them. Please re-enable for inference!\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# NOTE: this is just an example! you do not have to wait for this progressbar to finish :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQUlqoEAulB8"
      },
      "source": [
        "### Final task: *actually* train the model (4 points)\n",
        "\n",
        "Your task is to fine-tune the model to _generate python code_. Please use the above examples for inspiration. More specifically,\n",
        "\n",
        "* __dataset:__ use [codeparrot-clean](https://huggingface.co/datasets/codeparrot/codeparrot-clean) or any other data containing python code. Since you do not need much data for this excercise, it is enough to use just shorter validation subset of `codeparrots`\n",
        "* __preprocessing:__ select python code based on file extentions (.py)  (may skip in case of codeparrot - it is 100% python)\n",
        "* __short lines:__ please take the first 512 characters of each line\n",
        "* __adapter type:__ please use LoRA as defined above __plus at least one of:__\n",
        "   - extra adapter on lm_head\n",
        "   - extra adapter on MLP components (mlp.*)\n",
        "   - trainable input embeddings (requires tweaking memory usage)\n",
        "\n",
        "* __training:__ you do not have to train to convergence. If all goes well, your model should `.generate` code after 500 steps. Please use batch size of at least 4 (4 x 1 x 512 tokens) using `gradient_accumulation_steps=4`.\n",
        "\n",
        "\n",
        "Note: the peft library also has LoRA implementation. However, we ask that for this assignment you show at least one complete training run with your own LoRA code.\n",
        "\n",
        "__Alternative assignment:__ Instead of doing python code, feel free to substitute the task with any other dataset, e.g. your favorite artist or podcast, as long as it's ethical. If you choose your own task, please show examples of what your model learned - or did not learn, akin to the code examples below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "py_dataset = datasets.load_dataset('codeparrot/codeparrot-clean-valid')\n",
        "py_dataset_token = py_dataset.map(lambda samples: tokenizer(samples['content'], truncation=True, max_length=512), batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "a7be9fd6ffe94f839ca09fd170c3f386",
            "20826c486b3c4349a036b41b01fb743a",
            "2c5293b052f343d2b3f78d468b8fe94e",
            "db9518986d7f4ea78dd0e27c2cd08e91",
            "ad7b9c6a28874021868bb9c9aba4b3f8",
            "16004f6af1ac4a3684b5dc5126414ef2",
            "1f9a3847acd440c583ecfa5714b66c7b",
            "62d1896afebf455fb82219457834b8ac",
            "b1b1b0a32b98472485f6ae114be74de5",
            "7ded812540ef4bcebb14e6130617fe26",
            "5fa1b2699f324dec8a9d094e3b67ffc1"
          ]
        },
        "id": "cL_mjsPnnnb_",
        "outputId": "c6fb202c-a738-4185-cd5b-d122e317ec7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/61373 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7be9fd6ffe94f839ca09fd170c3f386"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_LfFWSYhulB8"
      },
      "outputs": [],
      "source": [
        "prompts =  ['', 'import', 'from', 'while', 'try', 'if', 'for', 'torch']  # feel free to add a few more that are not 100% assiciated with Python\n",
        "\n",
        "# generate baseline samples with the selected prompts before finetuning\n",
        "# please feel free to use transformers.Trainer (as above) or your custom training code\n",
        "# after the training concludes, please show examples of text generated by your model. It is expected to look like Python code fragments\n",
        "# print the generation examples nicely (suggestion: use pandas or HTML) for easier comparison\n",
        "# note: your LoRA-enhanced model can run generation the same way as the non-trained model (above)\n",
        "\n",
        "baseline_samples = []\n",
        "for prompt in prompts:\n",
        "  batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "  for i in range(30):\n",
        "      next_token = model(**batch).logits[0, -1].argmax(-1).reshape(1, 1)\n",
        "      batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
        "      batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
        "  baseline_samples.append(tokenizer.decode(batch['input_ids'][0].cpu().numpy().tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aun3LZhxp-Rv",
        "outputId": "b0be4347-5b25-4df6-c956-7cdbe3f7f414"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s> 2019-2020 School Year\\nThe 2019-2020 school year is here',\n",
              " '<s>import Foundation\\n\\npublic extension NSURL {\\n    public var absoluteString: String {\\n        return String(cString: CFBundleGetBundleWith',\n",
              " '<s>from __future__ import absolute_import\\nfrom __future__ import division\\nfrom __future__ import print_function\\n\\nimport os',\n",
              " '<s>while(1)\\nwhile(1) {\\n    // do something\\n}\\n\\\\end{code}\\n\\nComment: This is not the',\n",
              " '<s>try to find the best solution for your needs.\\nWe are a team of professionals with a long experience in the field of web development.\\nWe',\n",
              " '<s>if ( !window.atmosphere ) {\\n    window.atmosphere = {};\\n}\\n\\n(function () {\\n    var o',\n",
              " '<s>for the 2019-2020 school year.\\nThe application process for the 2019-2020',\n",
              " '<s>torchbearer 2017-05-18 19:55:25 UTC #1\\nIm']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRALayer(nn.Module):\n",
        "    \"\"\"Wraps a linear layer with LoRA-like adapter. Wraps an existing OPT linear layer\"\"\"\n",
        "    def __init__(self, module: nn.Linear, rank: int):\n",
        "        super().__init__()\n",
        "        self.module = module  # pre-trained (frozen) linear layer\n",
        "        self.adapter_A = nn.Parameter(torch.empty(module.in_features, rank, device=module.weight.device))\n",
        "        nn.init.kaiming_uniform_(self.adapter_A, a=5 ** 0.5)\n",
        "        self.adapter_B = nn.Parameter(torch.zeros(rank, module.out_features, device=module.weight.device))\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Apply self.module and LoRA adapter, return the sum (self.module outputs + adapter outputs)\n",
        "        module_output = self.module(input)\n",
        "        adapter_output = torch.matmul(torch.matmul(input, self.adapter_A), self.adapter_B)\n",
        "        return module_output + adapter_output"
      ],
      "metadata": {
        "id": "kMXsMOtfqC33"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test your implementation\n",
        "test_linear = nn.Linear(128, 128)\n",
        "test_linear.weight.data[...] = torch.eye(128)\n",
        "test_adapter = LoRALayer(test_linear, rank=8)\n",
        "\n",
        "assert torch.allclose(test_adapter(torch.ones(1, 1, 128)), test_linear.bias + 1), \"please check your forward pass\"\n",
        "\n",
        "test_adapter.adapter_A.data[...] = torch.linspace(0.1, -0.5, 128 * 8).view(128, 8)\n",
        "test_adapter.adapter_B.data[...] = torch.linspace(0.5, -0.1, 128 * 8).view(8, 128)\n",
        "test_linear.bias.data[...] = torch.linspace(1., -1., 128)\n",
        "\n",
        "dummy_loss = F.mse_loss(test_adapter(torch.ones(1, 128) / 128).squeeze(), torch.linspace(-1, 1, 128))\n",
        "assert torch.allclose(dummy_loss, torch.tensor(1.3711389), rtol=0, atol=1e-4)\n",
        "dummy_loss.backward()\n",
        "assert all(w.grad is not None for w in [test_adapter.adapter_A, test_adapter.adapter_B]), \"some adapter weights have no grad\"\n",
        "assert torch.allclose(test_adapter.adapter_A.grad.sum(), torch.tensor(-0.60158), rtol=0, atol=1e-4), \"bad grad w.r.t. A\"\n",
        "assert torch.allclose(test_adapter.adapter_B.grad.sum(), torch.tensor(0.9931), rtol=0, atol=1e-4), \"bad grad w.r.t. B\"\n",
        "# note: bad grad means that your code is different from LoRA paper OR that your code is not autograd-friendly (e.g. no_grad)\n",
        "del dummy_loss, test_linear, test_adapter\n",
        "print(\"All tests passed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpyU4elwqPHl",
        "outputId": "093dda90-d957-4b03-c8de-3cca4a858ce6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_name, device_map='auto', low_cpu_mem_usage=True, offload_state_dict=True,\n",
        "    load_in_4bit=True, torch_dtype=torch.float32,  # weights are 4-bit; layernorms and activations are fp32\n",
        ")\n",
        "for param in lora_model.parameters():\n",
        "    param.requires_grad=False\n",
        "lora_model.gradient_checkpointing_enable()\n",
        "lora_model.enable_input_require_grads()\n",
        "\n",
        "lora_rank = 8\n",
        "\n",
        "for name, module in lora_model.model.layers.named_modules():\n",
        "    if 'LlamaDecoderLayer' in repr(type(module)):\n",
        "          module.mlp.gate_proj = LoRALayer(module.mlp.gate_proj, rank=lora_rank).to(device)\n",
        "          module.mlp.up_proj = LoRALayer(module.mlp.up_proj, rank=lora_rank).to(device)\n",
        "          module.mlp.down_proj = LoRALayer(module.mlp.down_proj, rank=lora_rank).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ab530aa2bcfb44599a5ff101ec0e074b",
            "96fa796463b44ca299141cbfdb3e7c26",
            "6e69c50923dd4271b75df06d4b46be95",
            "2598bf59338f4c93a477bbfe01a0c08e",
            "76c8af682c444cf792d4efc720149550",
            "a0556b7c217c4338abe310e03fe0c273",
            "961d6543c9f24593ad2ee0764efe7db0",
            "189f578045ac4bacaeeebb915fa51852",
            "7d45ab9d3fb44d9da036b0e04c88be9b",
            "2d86df3aabf347bd81f8056fc0321cd4",
            "3d011325c7914c25a8bea1d1e7b441a6"
          ]
        },
        "id": "Tep9oPU8qY_k",
        "outputId": "6c1fa374-8c8f-4968-bb9e-697ee81e1388"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab530aa2bcfb44599a5ff101ec0e074b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_model._hf_peft_config_loaded = True  # silence a warning from HF trainer\n",
        "lora_model.config.use_cache = False\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=lora_model, train_dataset=py_dataset_token['train'],\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=4, gradient_accumulation_steps=4,\n",
        "        # note: if you want larger batch size, increase gradient_accumulation_steps\n",
        "        warmup_steps=100, max_steps=100, learning_rate=2e-4, fp16=True,\n",
        "        logging_steps=2, output_dir='outputs', report_to=None),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "# if you see cache warnings, set `model.config.use_cache = False` to silence them. Please re-enable for inference!\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qt9YLHbIqnW5",
        "outputId": "d8460609-8eb4-49e8-afc0-c2db275224c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 45:53, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.081300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.095200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.095400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.011800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.181600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.085000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.075400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.126400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.099200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.030400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.049600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.100700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.065400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.015200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.083200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.074800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.103600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.149700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.061100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.129800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.979000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.063000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.897700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.053000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.967000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.938100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.891000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.977700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.993400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.971100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.020400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.967100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.071600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.974600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.946100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.050900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.904600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.993000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.095600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.042400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.936200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.107500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=1.0436521255970002, metrics={'train_runtime': 2781.7307, 'train_samples_per_second': 0.575, 'train_steps_per_second': 0.036, 'total_flos': 3.25334310322176e+16, 'train_loss': 1.0436521255970002, 'epoch': 0.03})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate peft samples with the selected prompts before finetuning\n",
        "prompts =  ['', 'import', 'from', 'while', 'try', 'if', 'for', 'torch']\n",
        "samples = []\n",
        "for prompt in prompts:\n",
        "  batch = tokenizer(prompt, return_tensors='pt', return_token_type_ids=False).to(device)\n",
        "  for i in range(30):\n",
        "      next_token = lora_model(**batch).logits[0, -1].argmax(-1).reshape(1, 1)\n",
        "      batch['input_ids'] = torch.cat([batch['input_ids'], next_token], dim=-1)\n",
        "      batch['attention_mask'] = torch.cat([batch['attention_mask'], torch.ones_like(next_token)], dim=-1)\n",
        "\n",
        "  samples.append(tokenizer.decode(batch['input_ids'][0].cpu().numpy().tolist()))"
      ],
      "metadata": {
        "id": "T5EfbDWKrd52"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmvh2mXGry6w",
        "outputId": "08b8c422-442f-409c-9ae7-5b5c9bb8e3c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s># -*- coding: utf-8 -*-\\n# Copyright 2015 Google Inc. All Rights Reserved.\\n',\n",
              " '<s>import os\\nimport sys\\nimport time\\nimport traceback\\nimport logging\\nimport logging.handlers\\nimport logging.config\\nimport logging.config',\n",
              " '<s>from __future__ import unicode_literals\\n\\nfrom django.db import models\\nfrom django.utils.encoding import python_2_unic',\n",
              " '<s>while (true) {\\n    print(\"Hello, world!\");\\n    print(\"Hello, world!\");\\n    print(\"Hello, world!\");\\n   ',\n",
              " '<s>try:\\n    from django.conf.urls import patterns, url\\nexcept ImportError:\\n    from django.conf.urls.defaults import',\n",
              " \"<s>if ( ! defined( 'ABSPATH' ) ) {\\n    exit;\\n}\\n\\n/**\\n * @class  WPBak\",\n",
              " '<s>for (var i = 0; i < 10000000000000000000',\n",
              " \"<s>torch.math.Tensor = torch.class('torch.math.Tensor', function()\\n  local function new(t)\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SSucUeB4ulB9",
        "outputId": "e3ddec58-479b-405d-8f60-cc1b2b8879c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table style=\"border:1px solid black\" >\n",
              "  <tr>\n",
              "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">``</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"> 2019-2020 School Year\n",
              "The 2019-2020 school year is here</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\"># -*- coding: utf-8 -*-\n",
              "# Copyright 2015 Google Inc. All Rights Reserved.\n",
              "</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`import`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">import Foundation\n",
              "\n",
              "public extension NSURL {\n",
              "    public var absoluteString: String {\n",
              "        return String(cString: CFBundleGetBundleWith</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">import os\n",
              "import sys\n",
              "import time\n",
              "import traceback\n",
              "import logging\n",
              "import logging.handlers\n",
              "import logging.config\n",
              "import logging.config</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`from`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">from __future__ import absolute_import\n",
              "from __future__ import division\n",
              "from __future__ import print_function\n",
              "\n",
              "import os</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">from __future__ import unicode_literals\n",
              "\n",
              "from django.db import models\n",
              "from django.utils.encoding import python_2_unic</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`while`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">while(1)\n",
              "while(1) {\n",
              "    // do something\n",
              "}\n",
              "\\end{code}\n",
              "\n",
              "Comment: This is not the</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">while (true) {\n",
              "    print(\"Hello, world!\");\n",
              "    print(\"Hello, world!\");\n",
              "    print(\"Hello, world!\");\n",
              "   </pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`try`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">try to find the best solution for your needs.\n",
              "We are a team of professionals with a long experience in the field of web development.\n",
              "We</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">try:\n",
              "    from django.conf.urls import patterns, url\n",
              "except ImportError:\n",
              "    from django.conf.urls.defaults import</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`if`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">if ( !window.atmosphere ) {\n",
              "    window.atmosphere = {};\n",
              "}\n",
              "\n",
              "(function () {\n",
              "    var o</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">if ( ! defined( 'ABSPATH' ) ) {\n",
              "    exit;\n",
              "}\n",
              "\n",
              "/**\n",
              " * @class  WPBak</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`for`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">for the 2019-2020 school year.\n",
              "The application process for the 2019-2020</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">for (var i = 0; i < 10000000000000000000</pre></td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`torch`</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">torchbearer 2017-05-18 19:55:25 UTC #1\n",
              "Im</pre></td>\n",
              "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">torch.math.Tensor = torch.class('torch.math.Tensor', function()\n",
              "  local function new(t)\n",
              "</pre></td>\n",
              "  </tr>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# This template helps to compare generated code samples in pretty table form\n",
        "# feel free to present your work in other forms\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "table_template = \"\"\"<table style=\"border:1px solid black\" >\n",
        "  <tr>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PROMPT</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">BEFORE</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">AFTER</th>\n",
        "  </tr>\n",
        "{}\n",
        "</table>\"\"\"\n",
        "\n",
        "row_template = '''  <tr>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`{}`</pre></td>\n",
        "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:40%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "  </tr>'''\n",
        "\n",
        "rows = []\n",
        "\n",
        "for prompt, baseline, sample in zip(prompts, baseline_samples, samples):\n",
        "    # replace placeholders in the format() arguments\n",
        "    # rows.append(row_template.format(prompt, \"BEFORE FINETUNING\", \"TO BE GENERATED AFTER FINETUNING\"))\n",
        "    rows.append(row_template.format(prompt, baseline[3:], sample[3:]))\n",
        "\n",
        "display(HTML(table_template.format('\\n'.join(rows))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrKidv5KulB9"
      },
      "source": [
        "If you reach this: congratulations! you've completed everything in this practice session.\n",
        "\n",
        "If you want to dig deeper, try to implement prompt-tuning (for bonus points!).\n",
        "You can read more about prompt tuning variants in paper [1](https://arxiv.org/abs/2104.08691) or paper [2](https://arxiv.org/abs/2101.00190). Both versions can be implemented by passing trainable prompts as `model.forward(..., past_key_values=your_prompts)`.\n",
        "\n",
        "\n",
        "\n",
        "### Read more\n",
        "\n",
        "* How post-training quantization works: https://arxiv.org/abs/2208.07339\n",
        "* An overview of running large models: https://huggingface.co/docs/accelerate/package_reference/big_modeling\n",
        "* A general library for different adapter types: https://adapterhub.ml/\n",
        "\n",
        "\n",
        "### [extra info] Running other models.\n",
        "\n",
        "This notebook's code can run with other models of similar size, such as [Falcon-7B](https://huggingface.co/tiiuae/falcon-7b), [OPT-6.7B](https://huggingface.co/facebook/opt-6.7b) or [BLOOM-7.1B](https://huggingface.co/bigscience/bloom-7b1). However, they will require minor code tweaks:\n",
        "1. change the model name in `AutoModelForCausalLM.from_pretrained()` __and__ `AutoTokenizer`\n",
        "2. In the prompt tuning code, change `model.model.embed_tokens` to refer to the target model's word embeddings. Simply `print(model)` to navigate to them.\n",
        "3. Change code to add Lora layers - specifically where you what the transformer block components, since those components now have different names."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a329a6a8b64744a89169ad95ebdabaa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_858e81c7a88747338400a8628c23cdbd",
              "IPY_MODEL_b255ffb1028948ac8f60e77b9221db39",
              "IPY_MODEL_b12ec7cfaaf3407ebf0406ab77734b8f"
            ],
            "layout": "IPY_MODEL_d406425bcbdb4d43a56c3daee817293b"
          }
        },
        "858e81c7a88747338400a8628c23cdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ae8fbe36c54d658d549339d90d1944",
            "placeholder": "",
            "style": "IPY_MODEL_d89739d602374604aa24d738426b527b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b255ffb1028948ac8f60e77b9221db39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b775b1a1571840c4a4a0148ca4f0bc61",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbf2db5922824438840f45fc4b74ae72",
            "value": 33
          }
        },
        "b12ec7cfaaf3407ebf0406ab77734b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba542e31f14c4ca19dd144890d9afde2",
            "placeholder": "",
            "style": "IPY_MODEL_3c50d988d3e543a79ddb352a77a5a50b",
            "value": " 33/33 [02:13&lt;00:00,  4.11s/it]"
          }
        },
        "d406425bcbdb4d43a56c3daee817293b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5ae8fbe36c54d658d549339d90d1944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89739d602374604aa24d738426b527b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b775b1a1571840c4a4a0148ca4f0bc61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf2db5922824438840f45fc4b74ae72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba542e31f14c4ca19dd144890d9afde2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c50d988d3e543a79ddb352a77a5a50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39ac305e3f324b3f8eea2ec632e2f39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c97662de5524e559f30020db379558e",
              "IPY_MODEL_bb6641fbf9ae4eed87a7be96b9dadb6b",
              "IPY_MODEL_198a6e41a37545f18264c3eb1ea7907c"
            ],
            "layout": "IPY_MODEL_6d094b23993d41b9a72dca4ba98c6bba"
          }
        },
        "3c97662de5524e559f30020db379558e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e46427e479410c8b67bd9e01a05be6",
            "placeholder": "",
            "style": "IPY_MODEL_e5ca6cbc9bba431d934c4016381fe517",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "bb6641fbf9ae4eed87a7be96b9dadb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e66dcdd2ee44b89e07dc1e0bc6b401",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b15e7e3336e94438916f784ca820d43d",
            "value": 33
          }
        },
        "198a6e41a37545f18264c3eb1ea7907c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22208d8762a24cb59b775d05055618b6",
            "placeholder": "",
            "style": "IPY_MODEL_91e369c44ef245d4b740dfdc3259d9c3",
            "value": " 33/33 [02:25&lt;00:00,  4.52s/it]"
          }
        },
        "6d094b23993d41b9a72dca4ba98c6bba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e46427e479410c8b67bd9e01a05be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ca6cbc9bba431d934c4016381fe517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70e66dcdd2ee44b89e07dc1e0bc6b401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15e7e3336e94438916f784ca820d43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22208d8762a24cb59b775d05055618b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e369c44ef245d4b740dfdc3259d9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eb3ecfcbdf24b23ba8ca84781dacb0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_706396b698834bb9b097ed58597322a5",
              "IPY_MODEL_16d0d9d3a38340e3a4c4503a4478ac17",
              "IPY_MODEL_aaa70432b21f489784b04ef82a59786c"
            ],
            "layout": "IPY_MODEL_49a6a5cd71d7451890d8b3cd293e9b27"
          }
        },
        "706396b698834bb9b097ed58597322a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d7254f1a78c4717b682effd1ff29e56",
            "placeholder": "",
            "style": "IPY_MODEL_5e47bc789124454a92f0641754819846",
            "value": "Downloading readme: 100%"
          }
        },
        "16d0d9d3a38340e3a4c4503a4478ac17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5016c9b3498f4d2aaefe41fce53e391d",
            "max": 5554,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf4159bcbd3d4c65aba85e0fec0cd99e",
            "value": 5554
          }
        },
        "aaa70432b21f489784b04ef82a59786c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be89da3a2cec4974944768aa57bea11d",
            "placeholder": "",
            "style": "IPY_MODEL_e9032f92777149ebb6d9fc731bf6ca5d",
            "value": " 5.55k/5.55k [00:00&lt;00:00, 308kB/s]"
          }
        },
        "49a6a5cd71d7451890d8b3cd293e9b27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d7254f1a78c4717b682effd1ff29e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e47bc789124454a92f0641754819846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5016c9b3498f4d2aaefe41fce53e391d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4159bcbd3d4c65aba85e0fec0cd99e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be89da3a2cec4974944768aa57bea11d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9032f92777149ebb6d9fc731bf6ca5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02a7585097f84b66aebd751de8da0f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cd4214f933d4af29e50894638133822",
              "IPY_MODEL_6d759ddbb1f54171a1ee0573badd9494",
              "IPY_MODEL_4df241f871044c4883dc48b718980d92"
            ],
            "layout": "IPY_MODEL_9d52e41f13b6463eb9a112753fb3b436"
          }
        },
        "0cd4214f933d4af29e50894638133822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eea5c1a381d4c7297d54f9a6df26ac8",
            "placeholder": "",
            "style": "IPY_MODEL_ca053a6586a34247b0807a0944df37f0",
            "value": "Downloading data files: 100%"
          }
        },
        "6d759ddbb1f54171a1ee0573badd9494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98904bd648814109baf6065a09689c19",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8d3352ea16e4b15bf48b9328f1426a8",
            "value": 1
          }
        },
        "4df241f871044c4883dc48b718980d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf77db4d4ff40839a96cd30a6205cac",
            "placeholder": "",
            "style": "IPY_MODEL_66a69c3957b241b087e5876189de55b0",
            "value": " 1/1 [00:01&lt;00:00,  1.39s/it]"
          }
        },
        "9d52e41f13b6463eb9a112753fb3b436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eea5c1a381d4c7297d54f9a6df26ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca053a6586a34247b0807a0944df37f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98904bd648814109baf6065a09689c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d3352ea16e4b15bf48b9328f1426a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edf77db4d4ff40839a96cd30a6205cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a69c3957b241b087e5876189de55b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30c91da2c9b04ebca063b8617b7e89f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3258a9d352b48e7ae01e3144926e440",
              "IPY_MODEL_34099d8a6ea14ffdadfa49c548a7f9c6",
              "IPY_MODEL_da88d4f959ad49abb35b3b01e37d2c4e"
            ],
            "layout": "IPY_MODEL_2680953fa70c42cf9151ccbc01e74eee"
          }
        },
        "e3258a9d352b48e7ae01e3144926e440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e90ddfb610e645a4b92a9ff3a4a1cfb9",
            "placeholder": "",
            "style": "IPY_MODEL_3fbfd9c3b3284a549a318471d909a1ad",
            "value": "Downloading data: 100%"
          }
        },
        "34099d8a6ea14ffdadfa49c548a7f9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5bea63f1c484bbab47693e83be6d5ab",
            "max": 646739,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6955812674514ddeb517c3519479e572",
            "value": 646739
          }
        },
        "da88d4f959ad49abb35b3b01e37d2c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb05f16e8f7a472aa6c0429dab56f51a",
            "placeholder": "",
            "style": "IPY_MODEL_743acf7508644f5d926ea4996b100651",
            "value": " 647k/647k [00:01&lt;00:00, 471kB/s]"
          }
        },
        "2680953fa70c42cf9151ccbc01e74eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e90ddfb610e645a4b92a9ff3a4a1cfb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fbfd9c3b3284a549a318471d909a1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5bea63f1c484bbab47693e83be6d5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6955812674514ddeb517c3519479e572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb05f16e8f7a472aa6c0429dab56f51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "743acf7508644f5d926ea4996b100651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9be683454d72411aa7510e4921dfad3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_056079080e6341abbf85f9e83b8fc34e",
              "IPY_MODEL_4f323495be4f47c9a319d3a0037273ae",
              "IPY_MODEL_4f2e79bdf7bf4bf1b054cdf6532813cc"
            ],
            "layout": "IPY_MODEL_706a3ed1bdf3416fa00c08b44e8a333a"
          }
        },
        "056079080e6341abbf85f9e83b8fc34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_226895417e134d669f6745bb5d3df801",
            "placeholder": "",
            "style": "IPY_MODEL_aadd4898ec3b4b85b6669c2ac1f05a09",
            "value": "Extracting data files: 100%"
          }
        },
        "4f323495be4f47c9a319d3a0037273ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa02f59ef94484da6b80b53cae8dfff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08c050680a484a60aa8750d6cac45954",
            "value": 1
          }
        },
        "4f2e79bdf7bf4bf1b054cdf6532813cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4abe53249054f6681c7f9cf0bf6e511",
            "placeholder": "",
            "style": "IPY_MODEL_9aa8c435f20a4f3196c659664c876983",
            "value": " 1/1 [00:00&lt;00:00, 47.70it/s]"
          }
        },
        "706a3ed1bdf3416fa00c08b44e8a333a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "226895417e134d669f6745bb5d3df801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aadd4898ec3b4b85b6669c2ac1f05a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfa02f59ef94484da6b80b53cae8dfff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c050680a484a60aa8750d6cac45954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4abe53249054f6681c7f9cf0bf6e511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa8c435f20a4f3196c659664c876983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ee71b6786064a24aa3363dbd06b6922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a200ee71463f45e8932b5f8ec1526513",
              "IPY_MODEL_87c123d817244f8890ed6c4031f79e4d",
              "IPY_MODEL_2fbc1f01584b4ddea111d8ec6e6d0685"
            ],
            "layout": "IPY_MODEL_e9692c35afd94173a876f9dc2d5f2d07"
          }
        },
        "a200ee71463f45e8932b5f8ec1526513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de6b07d47bb241e6ac59c5c5beb3a99c",
            "placeholder": "",
            "style": "IPY_MODEL_b15ec39fa2f04d7f9ca49b4c4b63c734",
            "value": "Generating train split: "
          }
        },
        "87c123d817244f8890ed6c4031f79e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d75b5e23e1724cd2a7102019e76ad376",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1164b8c26fe24602ba38b00fd1353bdb",
            "value": 1
          }
        },
        "2fbc1f01584b4ddea111d8ec6e6d0685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bacd536b97f2495a91c6a6dd05b72d6b",
            "placeholder": "",
            "style": "IPY_MODEL_8efcd648e0c14e408e0a798753c7ca20",
            "value": " 2508/0 [00:00&lt;00:00, 27448.01 examples/s]"
          }
        },
        "e9692c35afd94173a876f9dc2d5f2d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de6b07d47bb241e6ac59c5c5beb3a99c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15ec39fa2f04d7f9ca49b4c4b63c734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d75b5e23e1724cd2a7102019e76ad376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1164b8c26fe24602ba38b00fd1353bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bacd536b97f2495a91c6a6dd05b72d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8efcd648e0c14e408e0a798753c7ca20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d733b07b93354e568ca792e42104facd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0901b10cba4a466398ad776fde2c9b31",
              "IPY_MODEL_19b1fa310e584f8f99fb1e45b8ec321a",
              "IPY_MODEL_93bac674cbc349008dfc912e6e0da7d4"
            ],
            "layout": "IPY_MODEL_d21d6cd06aa34884996ce98ed6f20e30"
          }
        },
        "0901b10cba4a466398ad776fde2c9b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68e10453dfa34bfebaeafde9f94bc65c",
            "placeholder": "",
            "style": "IPY_MODEL_98e94f5a16dc4388bdfe24de5253242a",
            "value": "Map: 100%"
          }
        },
        "19b1fa310e584f8f99fb1e45b8ec321a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e544f81fe96f43b4b6d430864f95e1cf",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaedbdb4be834d009fd4cd6038fe9d48",
            "value": 32
          }
        },
        "93bac674cbc349008dfc912e6e0da7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_480261bc7b214a8699fa6b862a9d4876",
            "placeholder": "",
            "style": "IPY_MODEL_1d1913cebd9945c9a443bbaea1412f01",
            "value": " 32/32 [00:00&lt;00:00, 258.28 examples/s]"
          }
        },
        "d21d6cd06aa34884996ce98ed6f20e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68e10453dfa34bfebaeafde9f94bc65c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98e94f5a16dc4388bdfe24de5253242a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e544f81fe96f43b4b6d430864f95e1cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaedbdb4be834d009fd4cd6038fe9d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "480261bc7b214a8699fa6b862a9d4876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1913cebd9945c9a443bbaea1412f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7be9fd6ffe94f839ca09fd170c3f386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20826c486b3c4349a036b41b01fb743a",
              "IPY_MODEL_2c5293b052f343d2b3f78d468b8fe94e",
              "IPY_MODEL_db9518986d7f4ea78dd0e27c2cd08e91"
            ],
            "layout": "IPY_MODEL_ad7b9c6a28874021868bb9c9aba4b3f8"
          }
        },
        "20826c486b3c4349a036b41b01fb743a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16004f6af1ac4a3684b5dc5126414ef2",
            "placeholder": "",
            "style": "IPY_MODEL_1f9a3847acd440c583ecfa5714b66c7b",
            "value": "Map: 100%"
          }
        },
        "2c5293b052f343d2b3f78d468b8fe94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62d1896afebf455fb82219457834b8ac",
            "max": 61373,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1b1b0a32b98472485f6ae114be74de5",
            "value": 61373
          }
        },
        "db9518986d7f4ea78dd0e27c2cd08e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ded812540ef4bcebb14e6130617fe26",
            "placeholder": "",
            "style": "IPY_MODEL_5fa1b2699f324dec8a9d094e3b67ffc1",
            "value": " 61373/61373 [15:31&lt;00:00, 61.49 examples/s]"
          }
        },
        "ad7b9c6a28874021868bb9c9aba4b3f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16004f6af1ac4a3684b5dc5126414ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9a3847acd440c583ecfa5714b66c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62d1896afebf455fb82219457834b8ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1b1b0a32b98472485f6ae114be74de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ded812540ef4bcebb14e6130617fe26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fa1b2699f324dec8a9d094e3b67ffc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab530aa2bcfb44599a5ff101ec0e074b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96fa796463b44ca299141cbfdb3e7c26",
              "IPY_MODEL_6e69c50923dd4271b75df06d4b46be95",
              "IPY_MODEL_2598bf59338f4c93a477bbfe01a0c08e"
            ],
            "layout": "IPY_MODEL_76c8af682c444cf792d4efc720149550"
          }
        },
        "96fa796463b44ca299141cbfdb3e7c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0556b7c217c4338abe310e03fe0c273",
            "placeholder": "",
            "style": "IPY_MODEL_961d6543c9f24593ad2ee0764efe7db0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6e69c50923dd4271b75df06d4b46be95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_189f578045ac4bacaeeebb915fa51852",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d45ab9d3fb44d9da036b0e04c88be9b",
            "value": 33
          }
        },
        "2598bf59338f4c93a477bbfe01a0c08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d86df3aabf347bd81f8056fc0321cd4",
            "placeholder": "",
            "style": "IPY_MODEL_3d011325c7914c25a8bea1d1e7b441a6",
            "value": " 33/33 [02:10&lt;00:00,  4.10s/it]"
          }
        },
        "76c8af682c444cf792d4efc720149550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0556b7c217c4338abe310e03fe0c273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961d6543c9f24593ad2ee0764efe7db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "189f578045ac4bacaeeebb915fa51852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d45ab9d3fb44d9da036b0e04c88be9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d86df3aabf347bd81f8056fc0321cd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d011325c7914c25a8bea1d1e7b441a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}